{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Docling","text":"<p>Docling bundles PDF document conversion to JSON and Markdown in an easy, self-contained package.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\u26a1 Converts any PDF document to JSON or Markdown format, stable and lightning fast</li> <li>\ud83d\udcd1 Understands detailed page layout, reading order and recovers table structures</li> <li>\ud83d\udcdd Extracts metadata from the document, such as title, authors, references and language</li> <li>\ud83d\udd0d Includes OCR support for scanned PDFs</li> <li>\ud83e\udd16 Integrates easily with LLM app / RAG frameworks like LlamaIndex\u00a0\ud83e\udd99 &amp; LangChain\u00a0\ud83e\udd9c\ud83d\udd17</li> <li>\ud83d\udcbb Provides a simple and convenient CLI</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>To use Docling, simply install <code>docling</code> from your Python package manager, e.g. pip: <pre><code>pip install docling\n</code></pre></p> <p>Works on macOS, Linux, and Windows, with support for both x86_64 and arm64 architectures.</p> Alternative PyTorch distributions <p>The Docling models depend on the PyTorch library. Depending on your architecture, you might want to use a different distribution of <code>torch</code>. For example, you might want support for different accelerator or for a cpu-only version. All the different ways for installing <code>torch</code> are listed on their website https://pytorch.org/.</p> <p>One common situation is the installation on Linux systems with cpu-only support. In this case, we suggest the installation of Docling with the following options</p> <pre><code># Example for installing on the Linux cpu-only version\npip install docling --extra-index-url https://download.pytorch.org/whl/cpu\n</code></pre> Alternative OCR engines <p>Docling supports multiple OCR engines for processing scanned documents. The current version provides the following engines.</p> Engine Installation Usage EasyOCR Default in Docling or via <code>pip install easyocr</code>. <code>EasyOcrOptions</code> Tesseract System dependency. See description for Tesseract and Tesserocr below. <code>TesseractOcrOptions</code> Tesseract CLI System dependency. See description below. <code>TesseractCliOcrOptions</code> <p>The Docling <code>DocumentConverter</code> allows to choose the OCR engine with the <code>ocr_options</code> settings. For example</p> <pre><code>from docling.datamodel.base_models import ConversionStatus, PipelineOptions\nfrom docling.datamodel.pipeline_options import PipelineOptions, EasyOcrOptions, TesseractOcrOptions\nfrom docling.document_converter import DocumentConverter\n\npipeline_options = PipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = TesseractOcrOptions()  # Use Tesseract\n\ndoc_converter = DocumentConverter(\n    pipeline_options=pipeline_options,\n)\n</code></pre> <p>Tesseract installation</p> <p>Tesseract is a popular OCR engine which is available on most operating systems. For using this engine with Docling, Tesseract must be installed on your system, using the packaging tool of your choice. Below we provide example commands. After installing Tesseract you are expected to provide the path to its language files using the <code>TESSDATA_PREFIX</code> environment variable (note that it must terminate with a slash <code>/</code>).</p> macOS (via Homebrew)Debian-basedRHEL <pre><code>brew install tesseract leptonica pkg-config\nTESSDATA_PREFIX=/opt/homebrew/share/tessdata/\necho \"Set TESSDATA_PREFIX=${TESSDATA_PREFIX}\"\n</code></pre> <pre><code>apt-get install tesseract-ocr tesseract-ocr-eng libtesseract-dev libleptonica-dev pkg-config\nTESSDATA_PREFIX=$(dpkg -L tesseract-ocr-eng | grep tessdata$)\necho \"Set TESSDATA_PREFIX=${TESSDATA_PREFIX}\"\n</code></pre> <pre><code>dnf install tesseract tesseract-devel tesseract-langpack-eng leptonica-devel\nTESSDATA_PREFIX=/usr/share/tesseract/tessdata/\necho \"Set TESSDATA_PREFIX=${TESSDATA_PREFIX}\"\n</code></pre> <p>Linking to Tesseract The most efficient usage of the Tesseract library is via linking. Docling is using the Tesserocr package for this.</p> <p>If you get into installation issues of Tesserocr, we suggest using the following installation options:</p> <pre><code>pip uninstall tesserocr\npip install --no-binary :all: tesserocr\n</code></pre>"},{"location":"installation/#development-setup","title":"Development setup","text":"<p>To develop Docling features, bugfixes etc., install as follows from your local clone's root dir:</p> <pre><code>poetry install --all-extras\n</code></pre>"},{"location":"examples/batch_convert/","title":"Batch conversion","text":"In\u00a0[\u00a0]: Copied! <pre>import json\nimport logging\nimport time\nfrom pathlib import Path\nfrom typing import Iterable\n</pre> import json import logging import time from pathlib import Path from typing import Iterable In\u00a0[\u00a0]: Copied! <pre>from docling.datamodel.base_models import ConversionStatus\nfrom docling.datamodel.document import ConversionResult, DocumentConversionInput\nfrom docling.document_converter import DocumentConverter\n</pre> from docling.datamodel.base_models import ConversionStatus from docling.datamodel.document import ConversionResult, DocumentConversionInput from docling.document_converter import DocumentConverter In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>def export_documents(\n    conv_results: Iterable[ConversionResult],\n    output_dir: Path,\n):\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    success_count = 0\n    failure_count = 0\n    partial_success_count = 0\n\n    for conv_res in conv_results:\n        if conv_res.status == ConversionStatus.SUCCESS:\n            success_count += 1\n            doc_filename = conv_res.input.file.stem\n\n            # Export Deep Search document JSON format:\n            with (output_dir / f\"{doc_filename}.json\").open(\n                \"w\", encoding=\"utf-8\"\n            ) as fp:\n                fp.write(json.dumps(conv_res.render_as_dict()))\n\n            # Export Text format:\n            with (output_dir / f\"{doc_filename}.txt\").open(\"w\", encoding=\"utf-8\") as fp:\n                fp.write(conv_res.render_as_text())\n\n            # Export Markdown format:\n            with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n                fp.write(conv_res.render_as_markdown())\n\n            # Export Document Tags format:\n            with (output_dir / f\"{doc_filename}.doctags\").open(\n                \"w\", encoding=\"utf-8\"\n            ) as fp:\n                fp.write(conv_res.render_as_doctags())\n\n        elif conv_res.status == ConversionStatus.PARTIAL_SUCCESS:\n            _log.info(\n                f\"Document {conv_res.input.file} was partially converted with the following errors:\"\n            )\n            for item in conv_res.errors:\n                _log.info(f\"\\t{item.error_message}\")\n            partial_success_count += 1\n        else:\n            _log.info(f\"Document {conv_res.input.file} failed to convert.\")\n            failure_count += 1\n\n    _log.info(\n        f\"Processed {success_count + partial_success_count + failure_count} docs, \"\n        f\"of which {failure_count} failed \"\n        f\"and {partial_success_count} were partially converted.\"\n    )\n    return success_count, partial_success_count, failure_count\n</pre> def export_documents(     conv_results: Iterable[ConversionResult],     output_dir: Path, ):     output_dir.mkdir(parents=True, exist_ok=True)      success_count = 0     failure_count = 0     partial_success_count = 0      for conv_res in conv_results:         if conv_res.status == ConversionStatus.SUCCESS:             success_count += 1             doc_filename = conv_res.input.file.stem              # Export Deep Search document JSON format:             with (output_dir / f\"{doc_filename}.json\").open(                 \"w\", encoding=\"utf-8\"             ) as fp:                 fp.write(json.dumps(conv_res.render_as_dict()))              # Export Text format:             with (output_dir / f\"{doc_filename}.txt\").open(\"w\", encoding=\"utf-8\") as fp:                 fp.write(conv_res.render_as_text())              # Export Markdown format:             with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:                 fp.write(conv_res.render_as_markdown())              # Export Document Tags format:             with (output_dir / f\"{doc_filename}.doctags\").open(                 \"w\", encoding=\"utf-8\"             ) as fp:                 fp.write(conv_res.render_as_doctags())          elif conv_res.status == ConversionStatus.PARTIAL_SUCCESS:             _log.info(                 f\"Document {conv_res.input.file} was partially converted with the following errors:\"             )             for item in conv_res.errors:                 _log.info(f\"\\t{item.error_message}\")             partial_success_count += 1         else:             _log.info(f\"Document {conv_res.input.file} failed to convert.\")             failure_count += 1      _log.info(         f\"Processed {success_count + partial_success_count + failure_count} docs, \"         f\"of which {failure_count} failed \"         f\"and {partial_success_count} were partially converted.\"     )     return success_count, partial_success_count, failure_count In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_paths = [\n        Path(\"./tests/data/2206.01062.pdf\"),\n        Path(\"./tests/data/2203.01017v2.pdf\"),\n        Path(\"./tests/data/2305.03393v1.pdf\"),\n        Path(\"./tests/data/redp5110.pdf\"),\n        Path(\"./tests/data/redp5695.pdf\"),\n    ]\n\n    # buf = BytesIO(Path(\"./test/data/2206.01062.pdf\").open(\"rb\").read())\n    # docs = [DocumentStream(filename=\"my_doc.pdf\", stream=buf)]\n    # input = DocumentConversionInput.from_streams(docs)\n\n    doc_converter = DocumentConverter()\n\n    input = DocumentConversionInput.from_paths(input_doc_paths)\n\n    start_time = time.time()\n\n    conv_results = doc_converter.convert(input)\n    success_count, partial_success_count, failure_count = export_documents(\n        conv_results, output_dir=Path(\"./scratch\")\n    )\n\n    end_time = time.time() - start_time\n\n    _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")\n\n    if failure_count &gt; 0:\n        raise RuntimeError(\n            f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"\n        )\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_paths = [         Path(\"./tests/data/2206.01062.pdf\"),         Path(\"./tests/data/2203.01017v2.pdf\"),         Path(\"./tests/data/2305.03393v1.pdf\"),         Path(\"./tests/data/redp5110.pdf\"),         Path(\"./tests/data/redp5695.pdf\"),     ]      # buf = BytesIO(Path(\"./test/data/2206.01062.pdf\").open(\"rb\").read())     # docs = [DocumentStream(filename=\"my_doc.pdf\", stream=buf)]     # input = DocumentConversionInput.from_streams(docs)      doc_converter = DocumentConverter()      input = DocumentConversionInput.from_paths(input_doc_paths)      start_time = time.time()      conv_results = doc_converter.convert(input)     success_count, partial_success_count, failure_count = export_documents(         conv_results, output_dir=Path(\"./scratch\")     )      end_time = time.time() - start_time      _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")      if failure_count &gt; 0:         raise RuntimeError(             f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"         ) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/custom_convert/","title":"Custom conversion","text":"In\u00a0[\u00a0]: Copied! <pre>import json\nimport logging\nimport time\nfrom pathlib import Path\nfrom typing import Iterable\n</pre> import json import logging import time from pathlib import Path from typing import Iterable In\u00a0[\u00a0]: Copied! <pre>from docling.backend.docling_parse_backend import DoclingParseDocumentBackend\nfrom docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\nfrom docling.datamodel.base_models import ConversionStatus, PipelineOptions\nfrom docling.datamodel.document import ConversionResult, DocumentConversionInput\nfrom docling.datamodel.pipeline_options import (\n    TesseractCliOcrOptions,\n    TesseractOcrOptions,\n)\nfrom docling.document_converter import DocumentConverter\n</pre> from docling.backend.docling_parse_backend import DoclingParseDocumentBackend from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend from docling.datamodel.base_models import ConversionStatus, PipelineOptions from docling.datamodel.document import ConversionResult, DocumentConversionInput from docling.datamodel.pipeline_options import (     TesseractCliOcrOptions,     TesseractOcrOptions, ) from docling.document_converter import DocumentConverter In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>def export_documents(\n    conv_results: Iterable[ConversionResult],\n    output_dir: Path,\n):\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    success_count = 0\n    failure_count = 0\n\n    for conv_res in conv_results:\n        if conv_res.status == ConversionStatus.SUCCESS:\n            success_count += 1\n            doc_filename = conv_res.input.file.stem\n\n            # Export Deep Search document JSON format:\n            with (output_dir / f\"{doc_filename}.json\").open(\n                \"w\", encoding=\"utf-8\"\n            ) as fp:\n                fp.write(json.dumps(conv_res.render_as_dict()))\n\n            # Export Text format:\n            with (output_dir / f\"{doc_filename}.txt\").open(\"w\", encoding=\"utf-8\") as fp:\n                fp.write(conv_res.render_as_text())\n\n            # Export Markdown format:\n            with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n                fp.write(conv_res.render_as_markdown())\n\n            # Export Document Tags format:\n            with (output_dir / f\"{doc_filename}.doctags\").open(\n                \"w\", encoding=\"utf-8\"\n            ) as fp:\n                fp.write(conv_res.render_as_doctags())\n\n        else:\n            _log.info(f\"Document {conv_res.input.file} failed to convert.\")\n            failure_count += 1\n\n    _log.info(\n        f\"Processed {success_count + failure_count} docs, of which {failure_count} failed\"\n    )\n\n    return success_count, failure_count\n</pre> def export_documents(     conv_results: Iterable[ConversionResult],     output_dir: Path, ):     output_dir.mkdir(parents=True, exist_ok=True)      success_count = 0     failure_count = 0      for conv_res in conv_results:         if conv_res.status == ConversionStatus.SUCCESS:             success_count += 1             doc_filename = conv_res.input.file.stem              # Export Deep Search document JSON format:             with (output_dir / f\"{doc_filename}.json\").open(                 \"w\", encoding=\"utf-8\"             ) as fp:                 fp.write(json.dumps(conv_res.render_as_dict()))              # Export Text format:             with (output_dir / f\"{doc_filename}.txt\").open(\"w\", encoding=\"utf-8\") as fp:                 fp.write(conv_res.render_as_text())              # Export Markdown format:             with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:                 fp.write(conv_res.render_as_markdown())              # Export Document Tags format:             with (output_dir / f\"{doc_filename}.doctags\").open(                 \"w\", encoding=\"utf-8\"             ) as fp:                 fp.write(conv_res.render_as_doctags())          else:             _log.info(f\"Document {conv_res.input.file} failed to convert.\")             failure_count += 1      _log.info(         f\"Processed {success_count + failure_count} docs, of which {failure_count} failed\"     )      return success_count, failure_count In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_paths = [\n        Path(\"./tests/data/2206.01062.pdf\"),\n    ]\n\n    ###########################################################################\n\n    # The following sections contain a combination of PipelineOptions\n    # and PDF Backends for various configurations.\n    # Uncomment one section at the time to see the differences in the output.\n\n    # PyPdfium without EasyOCR\n    # --------------------\n    # pipeline_options = PipelineOptions()\n    # pipeline_options.do_ocr=False\n    # pipeline_options.do_table_structure=True\n    # pipeline_options.table_structure_options.do_cell_matching = False\n\n    # doc_converter = DocumentConverter(\n    #     pipeline_options=pipeline_options,\n    #     pdf_backend=PyPdfiumDocumentBackend,\n    # )\n\n    # PyPdfium with EasyOCR\n    # -----------------\n    # pipeline_options = PipelineOptions()\n    # pipeline_options.do_ocr=True\n    # pipeline_options.do_table_structure=True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n\n    # doc_converter = DocumentConverter(\n    #     pipeline_options=pipeline_options,\n    #     pdf_backend=PyPdfiumDocumentBackend,\n    # )\n\n    # Docling Parse without EasyOCR\n    # -------------------------\n    pipeline_options = PipelineOptions()\n    pipeline_options.do_ocr = False\n    pipeline_options.do_table_structure = True\n    pipeline_options.table_structure_options.do_cell_matching = True\n\n    doc_converter = DocumentConverter(\n        pipeline_options=pipeline_options,\n        pdf_backend=DoclingParseDocumentBackend,\n    )\n\n    # Docling Parse with EasyOCR\n    # ----------------------\n    # pipeline_options = PipelineOptions()\n    # pipeline_options.do_ocr=True\n    # pipeline_options.do_table_structure=True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n\n    # doc_converter = DocumentConverter(\n    #     pipeline_options=pipeline_options,\n    #     pdf_backend=DoclingParseDocumentBackend,\n    # )\n\n    # Docling Parse with Tesseract\n    # ----------------------\n    # pipeline_options = PipelineOptions()\n    # pipeline_options.do_ocr = True\n    # pipeline_options.do_table_structure = True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n    # pipeline_options.ocr_options = TesseractOcrOptions()\n\n    # doc_converter = DocumentConverter(\n    #     pipeline_options=pipeline_options,\n    #     pdf_backend=DoclingParseDocumentBackend,\n    # )\n\n    # Docling Parse with Tesseract CLI\n    # ----------------------\n    # pipeline_options = PipelineOptions()\n    # pipeline_options.do_ocr = True\n    # pipeline_options.do_table_structure = True\n    # pipeline_options.table_structure_options.do_cell_matching = True\n    # pipeline_options.ocr_options = TesseractCliOcrOptions()\n\n    # doc_converter = DocumentConverter(\n    #     pipeline_options=pipeline_options,\n    #     pdf_backend=DoclingParseDocumentBackend,\n    # )\n\n    ###########################################################################\n\n    # Define input files\n    input = DocumentConversionInput.from_paths(input_doc_paths)\n\n    start_time = time.time()\n\n    conv_results = doc_converter.convert(input)\n    success_count, failure_count = export_documents(\n        conv_results, output_dir=Path(\"./scratch\")\n    )\n\n    end_time = time.time() - start_time\n\n    _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")\n\n    if failure_count &gt; 0:\n        raise RuntimeError(\n            f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"\n        )\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_paths = [         Path(\"./tests/data/2206.01062.pdf\"),     ]      ###########################################################################      # The following sections contain a combination of PipelineOptions     # and PDF Backends for various configurations.     # Uncomment one section at the time to see the differences in the output.      # PyPdfium without EasyOCR     # --------------------     # pipeline_options = PipelineOptions()     # pipeline_options.do_ocr=False     # pipeline_options.do_table_structure=True     # pipeline_options.table_structure_options.do_cell_matching = False      # doc_converter = DocumentConverter(     #     pipeline_options=pipeline_options,     #     pdf_backend=PyPdfiumDocumentBackend,     # )      # PyPdfium with EasyOCR     # -----------------     # pipeline_options = PipelineOptions()     # pipeline_options.do_ocr=True     # pipeline_options.do_table_structure=True     # pipeline_options.table_structure_options.do_cell_matching = True      # doc_converter = DocumentConverter(     #     pipeline_options=pipeline_options,     #     pdf_backend=PyPdfiumDocumentBackend,     # )      # Docling Parse without EasyOCR     # -------------------------     pipeline_options = PipelineOptions()     pipeline_options.do_ocr = False     pipeline_options.do_table_structure = True     pipeline_options.table_structure_options.do_cell_matching = True      doc_converter = DocumentConverter(         pipeline_options=pipeline_options,         pdf_backend=DoclingParseDocumentBackend,     )      # Docling Parse with EasyOCR     # ----------------------     # pipeline_options = PipelineOptions()     # pipeline_options.do_ocr=True     # pipeline_options.do_table_structure=True     # pipeline_options.table_structure_options.do_cell_matching = True      # doc_converter = DocumentConverter(     #     pipeline_options=pipeline_options,     #     pdf_backend=DoclingParseDocumentBackend,     # )      # Docling Parse with Tesseract     # ----------------------     # pipeline_options = PipelineOptions()     # pipeline_options.do_ocr = True     # pipeline_options.do_table_structure = True     # pipeline_options.table_structure_options.do_cell_matching = True     # pipeline_options.ocr_options = TesseractOcrOptions()      # doc_converter = DocumentConverter(     #     pipeline_options=pipeline_options,     #     pdf_backend=DoclingParseDocumentBackend,     # )      # Docling Parse with Tesseract CLI     # ----------------------     # pipeline_options = PipelineOptions()     # pipeline_options.do_ocr = True     # pipeline_options.do_table_structure = True     # pipeline_options.table_structure_options.do_cell_matching = True     # pipeline_options.ocr_options = TesseractCliOcrOptions()      # doc_converter = DocumentConverter(     #     pipeline_options=pipeline_options,     #     pdf_backend=DoclingParseDocumentBackend,     # )      ###########################################################################      # Define input files     input = DocumentConversionInput.from_paths(input_doc_paths)      start_time = time.time()      conv_results = doc_converter.convert(input)     success_count, failure_count = export_documents(         conv_results, output_dir=Path(\"./scratch\")     )      end_time = time.time() - start_time      _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")      if failure_count &gt; 0:         raise RuntimeError(             f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"         ) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/export_figures/","title":"Figure export","text":"In\u00a0[\u00a0]: Copied! <pre>import logging\nimport time\nfrom pathlib import Path\nfrom typing import Tuple\n</pre> import logging import time from pathlib import Path from typing import Tuple In\u00a0[\u00a0]: Copied! <pre>from docling.datamodel.base_models import (\n    AssembleOptions,\n    ConversionStatus,\n    FigureElement,\n    PageElement,\n    TableElement,\n)\nfrom docling.datamodel.document import DocumentConversionInput\nfrom docling.document_converter import DocumentConverter\n</pre> from docling.datamodel.base_models import (     AssembleOptions,     ConversionStatus,     FigureElement,     PageElement,     TableElement, ) from docling.datamodel.document import DocumentConversionInput from docling.document_converter import DocumentConverter In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>IMAGE_RESOLUTION_SCALE = 2.0\n</pre> IMAGE_RESOLUTION_SCALE = 2.0 In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_paths = [\n        Path(\"./tests/data/2206.01062.pdf\"),\n    ]\n    output_dir = Path(\"./scratch\")\n\n    input_files = DocumentConversionInput.from_paths(input_doc_paths)\n\n    # Important: For operating with page images, we must keep them, otherwise the DocumentConverter\n    # will destroy them for cleaning up memory.\n    # This is done by setting AssembleOptions.images_scale, which also defines the scale of images.\n    # scale=1 correspond of a standard 72 DPI image\n    assemble_options = AssembleOptions()\n    assemble_options.images_scale = IMAGE_RESOLUTION_SCALE\n\n    doc_converter = DocumentConverter(assemble_options=assemble_options)\n\n    start_time = time.time()\n\n    conv_results = doc_converter.convert(input_files)\n\n    success_count = 0\n    failure_count = 0\n    output_dir.mkdir(parents=True, exist_ok=True)\n    for conv_res in conv_results:\n        if conv_res.status != ConversionStatus.SUCCESS:\n            _log.info(f\"Document {conv_res.input.file} failed to convert.\")\n            failure_count += 1\n            continue\n\n        doc_filename = conv_res.input.file.stem\n\n        # Export page images\n        for page in conv_res.pages:\n            page_no = page.page_no + 1\n            page_image_filename = output_dir / f\"{doc_filename}-{page_no}.png\"\n            with page_image_filename.open(\"wb\") as fp:\n                page.image.save(fp, format=\"PNG\")\n\n        # Export figures and tables\n        for element, image in conv_res.render_element_images(\n            element_types=(FigureElement, TableElement)\n        ):\n            element_image_filename = (\n                output_dir / f\"{doc_filename}-element-{element.id}.png\"\n            )\n            with element_image_filename.open(\"wb\") as fp:\n                image.save(fp, \"PNG\")\n\n        success_count += 1\n\n    end_time = time.time() - start_time\n\n    _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")\n\n    if failure_count &gt; 0:\n        raise RuntimeError(\n            f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"\n        )\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_paths = [         Path(\"./tests/data/2206.01062.pdf\"),     ]     output_dir = Path(\"./scratch\")      input_files = DocumentConversionInput.from_paths(input_doc_paths)      # Important: For operating with page images, we must keep them, otherwise the DocumentConverter     # will destroy them for cleaning up memory.     # This is done by setting AssembleOptions.images_scale, which also defines the scale of images.     # scale=1 correspond of a standard 72 DPI image     assemble_options = AssembleOptions()     assemble_options.images_scale = IMAGE_RESOLUTION_SCALE      doc_converter = DocumentConverter(assemble_options=assemble_options)      start_time = time.time()      conv_results = doc_converter.convert(input_files)      success_count = 0     failure_count = 0     output_dir.mkdir(parents=True, exist_ok=True)     for conv_res in conv_results:         if conv_res.status != ConversionStatus.SUCCESS:             _log.info(f\"Document {conv_res.input.file} failed to convert.\")             failure_count += 1             continue          doc_filename = conv_res.input.file.stem          # Export page images         for page in conv_res.pages:             page_no = page.page_no + 1             page_image_filename = output_dir / f\"{doc_filename}-{page_no}.png\"             with page_image_filename.open(\"wb\") as fp:                 page.image.save(fp, format=\"PNG\")          # Export figures and tables         for element, image in conv_res.render_element_images(             element_types=(FigureElement, TableElement)         ):             element_image_filename = (                 output_dir / f\"{doc_filename}-element-{element.id}.png\"             )             with element_image_filename.open(\"wb\") as fp:                 image.save(fp, \"PNG\")          success_count += 1      end_time = time.time() - start_time      _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")      if failure_count &gt; 0:         raise RuntimeError(             f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"         ) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/export_multimodal/","title":"Multimodal export","text":"In\u00a0[\u00a0]: Copied! <pre>import datetime\nimport logging\nimport time\nfrom pathlib import Path\n</pre> import datetime import logging import time from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[\u00a0]: Copied! <pre>from docling.datamodel.base_models import AssembleOptions, ConversionStatus\nfrom docling.datamodel.document import DocumentConversionInput\nfrom docling.document_converter import DocumentConverter\nfrom docling.utils.export import generate_multimodal_pages\n</pre> from docling.datamodel.base_models import AssembleOptions, ConversionStatus from docling.datamodel.document import DocumentConversionInput from docling.document_converter import DocumentConverter from docling.utils.export import generate_multimodal_pages In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>IMAGE_RESOLUTION_SCALE = 2.0\n</pre> IMAGE_RESOLUTION_SCALE = 2.0 In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_paths = [\n        Path(\"./tests/data/2206.01062.pdf\"),\n    ]\n    output_dir = Path(\"./scratch\")\n\n    input_files = DocumentConversionInput.from_paths(input_doc_paths)\n\n    # Important: For operating with page images, we must keep them, otherwise the DocumentConverter\n    # will destroy them for cleaning up memory.\n    # This is done by setting AssembleOptions.images_scale, which also defines the scale of images.\n    # scale=1 correspond of a standard 72 DPI image\n    assemble_options = AssembleOptions()\n    assemble_options.images_scale = IMAGE_RESOLUTION_SCALE\n\n    doc_converter = DocumentConverter(assemble_options=assemble_options)\n\n    start_time = time.time()\n\n    converted_docs = doc_converter.convert(input_files)\n\n    success_count = 0\n    failure_count = 0\n    output_dir.mkdir(parents=True, exist_ok=True)\n    for doc in converted_docs:\n        if doc.status != ConversionStatus.SUCCESS:\n            _log.info(f\"Document {doc.input.file} failed to convert.\")\n            failure_count += 1\n            continue\n\n        rows = []\n        for (\n            content_text,\n            content_md,\n            content_dt,\n            page_cells,\n            page_segments,\n            page,\n        ) in generate_multimodal_pages(doc):\n\n            dpi = page._default_image_scale * 72\n\n            rows.append(\n                {\n                    \"document\": doc.input.file.name,\n                    \"hash\": doc.input.document_hash,\n                    \"page_hash\": page.page_hash,\n                    \"image\": {\n                        \"width\": page.image.width,\n                        \"height\": page.image.height,\n                        \"bytes\": page.image.tobytes(),\n                    },\n                    \"cells\": page_cells,\n                    \"contents\": content_text,\n                    \"contents_md\": content_md,\n                    \"contents_dt\": content_dt,\n                    \"segments\": page_segments,\n                    \"extra\": {\n                        \"page_num\": page.page_no + 1,\n                        \"width_in_points\": page.size.width,\n                        \"height_in_points\": page.size.height,\n                        \"dpi\": dpi,\n                    },\n                }\n            )\n        success_count += 1\n\n    # Generate one parquet from all documents\n    df = pd.json_normalize(rows)\n    now = datetime.datetime.now()\n    output_filename = output_dir / f\"multimodal_{now:%Y-%m-%d_%H%M%S}.parquet\"\n    df.to_parquet(output_filename)\n\n    end_time = time.time() - start_time\n\n    _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")\n\n    if failure_count &gt; 0:\n        raise RuntimeError(\n            f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"\n        )\n\n    # This block demonstrates how the file can be opened with the HF datasets library\n    # from datasets import Dataset\n    # from PIL import Image\n    # multimodal_df = pd.read_parquet(output_filename)\n\n    # # Convert pandas DataFrame to Hugging Face Dataset and load bytes into image\n    # dataset = Dataset.from_pandas(multimodal_df)\n    # def transforms(examples):\n    #     examples[\"image\"] = Image.frombytes('RGB', (examples[\"image.width\"], examples[\"image.height\"]), examples[\"image.bytes\"], 'raw')\n    #     return examples\n    # dataset = dataset.map(transforms)\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_paths = [         Path(\"./tests/data/2206.01062.pdf\"),     ]     output_dir = Path(\"./scratch\")      input_files = DocumentConversionInput.from_paths(input_doc_paths)      # Important: For operating with page images, we must keep them, otherwise the DocumentConverter     # will destroy them for cleaning up memory.     # This is done by setting AssembleOptions.images_scale, which also defines the scale of images.     # scale=1 correspond of a standard 72 DPI image     assemble_options = AssembleOptions()     assemble_options.images_scale = IMAGE_RESOLUTION_SCALE      doc_converter = DocumentConverter(assemble_options=assemble_options)      start_time = time.time()      converted_docs = doc_converter.convert(input_files)      success_count = 0     failure_count = 0     output_dir.mkdir(parents=True, exist_ok=True)     for doc in converted_docs:         if doc.status != ConversionStatus.SUCCESS:             _log.info(f\"Document {doc.input.file} failed to convert.\")             failure_count += 1             continue          rows = []         for (             content_text,             content_md,             content_dt,             page_cells,             page_segments,             page,         ) in generate_multimodal_pages(doc):              dpi = page._default_image_scale * 72              rows.append(                 {                     \"document\": doc.input.file.name,                     \"hash\": doc.input.document_hash,                     \"page_hash\": page.page_hash,                     \"image\": {                         \"width\": page.image.width,                         \"height\": page.image.height,                         \"bytes\": page.image.tobytes(),                     },                     \"cells\": page_cells,                     \"contents\": content_text,                     \"contents_md\": content_md,                     \"contents_dt\": content_dt,                     \"segments\": page_segments,                     \"extra\": {                         \"page_num\": page.page_no + 1,                         \"width_in_points\": page.size.width,                         \"height_in_points\": page.size.height,                         \"dpi\": dpi,                     },                 }             )         success_count += 1      # Generate one parquet from all documents     df = pd.json_normalize(rows)     now = datetime.datetime.now()     output_filename = output_dir / f\"multimodal_{now:%Y-%m-%d_%H%M%S}.parquet\"     df.to_parquet(output_filename)      end_time = time.time() - start_time      _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")      if failure_count &gt; 0:         raise RuntimeError(             f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"         )      # This block demonstrates how the file can be opened with the HF datasets library     # from datasets import Dataset     # from PIL import Image     # multimodal_df = pd.read_parquet(output_filename)      # # Convert pandas DataFrame to Hugging Face Dataset and load bytes into image     # dataset = Dataset.from_pandas(multimodal_df)     # def transforms(examples):     #     examples[\"image\"] = Image.frombytes('RGB', (examples[\"image.width\"], examples[\"image.height\"]), examples[\"image.bytes\"], 'raw')     #     return examples     # dataset = dataset.map(transforms) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/export_tables/","title":"Table export","text":"In\u00a0[\u00a0]: Copied! <pre>import logging\nimport time\nfrom pathlib import Path\nfrom typing import Tuple\n</pre> import logging import time from pathlib import Path from typing import Tuple In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[\u00a0]: Copied! <pre>from docling.datamodel.base_models import ConversionStatus\nfrom docling.datamodel.document import DocumentConversionInput\nfrom docling.document_converter import DocumentConverter\n</pre> from docling.datamodel.base_models import ConversionStatus from docling.datamodel.document import DocumentConversionInput from docling.document_converter import DocumentConverter In\u00a0[\u00a0]: Copied! <pre>_log = logging.getLogger(__name__)\n</pre> _log = logging.getLogger(__name__) In\u00a0[\u00a0]: Copied! <pre>def main():\n    logging.basicConfig(level=logging.INFO)\n\n    input_doc_paths = [\n        Path(\"./tests/data/2206.01062.pdf\"),\n    ]\n    output_dir = Path(\"./scratch\")\n\n    input_files = DocumentConversionInput.from_paths(input_doc_paths)\n\n    doc_converter = DocumentConverter()\n\n    start_time = time.time()\n\n    conv_results = doc_converter.convert(input_files)\n\n    success_count = 0\n    failure_count = 0\n    output_dir.mkdir(parents=True, exist_ok=True)\n    for conv_res in conv_results:\n        if conv_res.status != ConversionStatus.SUCCESS:\n            _log.info(f\"Document {conv_res.input.file} failed to convert.\")\n            failure_count += 1\n            continue\n\n        doc_filename = conv_res.input.file.stem\n\n        # Export tables\n        for table_ix, table in enumerate(conv_res.output.tables):\n            table_df: pd.DataFrame = table.export_to_dataframe()\n            print(f\"## Table {table_ix}\")\n            print(table_df.to_markdown())\n\n            # Save the table as csv\n            element_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.csv\"\n            _log.info(f\"Saving CSV table to {element_csv_filename}\")\n            table_df.to_csv(element_csv_filename)\n\n            # Save the table as html\n            element_html_filename = (\n                output_dir / f\"{doc_filename}-table-{table_ix+1}.html\"\n            )\n            _log.info(f\"Saving HTML table to {element_html_filename}\")\n            with element_html_filename.open(\"w\") as fp:\n                fp.write(table.export_to_html())\n\n        success_count += 1\n\n    end_time = time.time() - start_time\n\n    _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")\n\n    if failure_count &gt; 0:\n        raise RuntimeError(\n            f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"\n        )\n</pre> def main():     logging.basicConfig(level=logging.INFO)      input_doc_paths = [         Path(\"./tests/data/2206.01062.pdf\"),     ]     output_dir = Path(\"./scratch\")      input_files = DocumentConversionInput.from_paths(input_doc_paths)      doc_converter = DocumentConverter()      start_time = time.time()      conv_results = doc_converter.convert(input_files)      success_count = 0     failure_count = 0     output_dir.mkdir(parents=True, exist_ok=True)     for conv_res in conv_results:         if conv_res.status != ConversionStatus.SUCCESS:             _log.info(f\"Document {conv_res.input.file} failed to convert.\")             failure_count += 1             continue          doc_filename = conv_res.input.file.stem          # Export tables         for table_ix, table in enumerate(conv_res.output.tables):             table_df: pd.DataFrame = table.export_to_dataframe()             print(f\"## Table {table_ix}\")             print(table_df.to_markdown())              # Save the table as csv             element_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.csv\"             _log.info(f\"Saving CSV table to {element_csv_filename}\")             table_df.to_csv(element_csv_filename)              # Save the table as html             element_html_filename = (                 output_dir / f\"{doc_filename}-table-{table_ix+1}.html\"             )             _log.info(f\"Saving HTML table to {element_html_filename}\")             with element_html_filename.open(\"w\") as fp:                 fp.write(table.export_to_html())          success_count += 1      end_time = time.time() - start_time      _log.info(f\"All documents were converted in {end_time:.2f} seconds.\")      if failure_count &gt; 0:         raise RuntimeError(             f\"The example failed converting {failure_count} on {len(input_doc_paths)}.\"         ) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"examples/minimal/","title":"Simple conversion","text":"In\u00a0[\u00a0]: Copied! <pre>from docling.document_converter import DocumentConverter\n</pre> from docling.document_converter import DocumentConverter In\u00a0[\u00a0]: Copied! <pre>source = \"https://arxiv.org/pdf/2408.09869\"  # PDF path or URL\nconverter = DocumentConverter()\ndoc = converter.convert_single(source)\nprint(doc.render_as_markdown())  # output: ## Docling Technical Report [...]\"\n</pre> source = \"https://arxiv.org/pdf/2408.09869\"  # PDF path or URL converter = DocumentConverter() doc = converter.convert_single(source) print(doc.render_as_markdown())  # output: ## Docling Technical Report [...]\""},{"location":"examples/rag_langchain/","title":"RAG with LangChain \ud83e\udd9c\ud83d\udd17","text":"In\u00a0[1]: Copied! <pre># requirements for this example:\n%pip install -qq docling docling-core python-dotenv langchain-text-splitters langchain-huggingface langchain-milvus\n</pre> # requirements for this example: %pip install -qq docling docling-core python-dotenv langchain-text-splitters langchain-huggingface langchain-milvus <pre>Note: you may need to restart the kernel to use updated packages.\n</pre> In\u00a0[2]: Copied! <pre>import os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n</pre> import os  from dotenv import load_dotenv  load_dotenv() Out[2]: <pre>True</pre> In\u00a0[3]: Copied! <pre>import warnings\n\nwarnings.filterwarnings(action=\"ignore\", category=UserWarning, module=\"pydantic|torch\")\nwarnings.filterwarnings(action=\"ignore\", category=FutureWarning, module=\"easyocr\")\n</pre> import warnings  warnings.filterwarnings(action=\"ignore\", category=UserWarning, module=\"pydantic|torch\") warnings.filterwarnings(action=\"ignore\", category=FutureWarning, module=\"easyocr\") <p>Below we set up:</p> <ul> <li>a <code>Loader</code> which will be used to create LangChain documents, and</li> <li>a splitter, which will be used to split these documents</li> </ul> In\u00a0[4]: Copied! <pre>from enum import Enum\nfrom typing import Iterator\n\nfrom langchain_core.document_loaders import BaseLoader\nfrom langchain_core.documents import Document as LCDocument\nfrom pydantic import BaseModel\n\nfrom docling.document_converter import DocumentConverter\n\n\nclass DocumentMetadata(BaseModel):\n    dl_doc_hash: str\n    # source: str\n\n\nclass DoclingPDFLoader(BaseLoader):\n    class ParseType(str, Enum):\n        MARKDOWN = \"markdown\"\n        # JSON = \"json\"\n\n    def __init__(self, file_path: str | list[str], parse_type: ParseType) -&gt; None:\n        self._file_paths = file_path if isinstance(file_path, list) else [file_path]\n        self._parse_type = parse_type\n        self._converter = DocumentConverter()\n\n    def lazy_load(self) -&gt; Iterator[LCDocument]:\n        for source in self._file_paths:\n            dl_doc = self._converter.convert_single(source).output\n            match self._parse_type:\n                case self.ParseType.MARKDOWN:\n                    text = dl_doc.export_to_markdown()\n                # case self.ParseType.JSON:\n                #     text = dl_doc.model_dump_json()\n                case _:\n                    raise RuntimeError(\n                        f\"Unexpected parse type encountered: {self._parse_type}\"\n                    )\n            lc_doc = LCDocument(\n                page_content=text,\n                metadata=DocumentMetadata(\n                    dl_doc_hash=dl_doc.file_info.document_hash,\n                ).model_dump(),\n            )\n            yield lc_doc\n</pre> from enum import Enum from typing import Iterator  from langchain_core.document_loaders import BaseLoader from langchain_core.documents import Document as LCDocument from pydantic import BaseModel  from docling.document_converter import DocumentConverter   class DocumentMetadata(BaseModel):     dl_doc_hash: str     # source: str   class DoclingPDFLoader(BaseLoader):     class ParseType(str, Enum):         MARKDOWN = \"markdown\"         # JSON = \"json\"      def __init__(self, file_path: str | list[str], parse_type: ParseType) -&gt; None:         self._file_paths = file_path if isinstance(file_path, list) else [file_path]         self._parse_type = parse_type         self._converter = DocumentConverter()      def lazy_load(self) -&gt; Iterator[LCDocument]:         for source in self._file_paths:             dl_doc = self._converter.convert_single(source).output             match self._parse_type:                 case self.ParseType.MARKDOWN:                     text = dl_doc.export_to_markdown()                 # case self.ParseType.JSON:                 #     text = dl_doc.model_dump_json()                 case _:                     raise RuntimeError(                         f\"Unexpected parse type encountered: {self._parse_type}\"                     )             lc_doc = LCDocument(                 page_content=text,                 metadata=DocumentMetadata(                     dl_doc_hash=dl_doc.file_info.document_hash,                 ).model_dump(),             )             yield lc_doc In\u00a0[5]: Copied! <pre>FILE_PATH = \"https://arxiv.org/pdf/2206.01062\"  # DocLayNet paper\n</pre> FILE_PATH = \"https://arxiv.org/pdf/2206.01062\"  # DocLayNet paper In\u00a0[6]: Copied! <pre>from langchain_text_splitters import RecursiveCharacterTextSplitter\n\nloader = DoclingPDFLoader(\n    file_path=FILE_PATH,\n    parse_type=DoclingPDFLoader.ParseType.MARKDOWN,\n)\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200,\n)\n</pre> from langchain_text_splitters import RecursiveCharacterTextSplitter  loader = DoclingPDFLoader(     file_path=FILE_PATH,     parse_type=DoclingPDFLoader.ParseType.MARKDOWN, ) text_splitter = RecursiveCharacterTextSplitter(     chunk_size=1000,     chunk_overlap=200, ) <pre>Fetching 7 files:   0%|          | 0/7 [00:00&lt;?, ?it/s]</pre> <p>We now used the above-defined objects to get the document splits:</p> In\u00a0[7]: Copied! <pre>docs = loader.load()\nsplits = text_splitter.split_documents(docs)\n</pre> docs = loader.load() splits = text_splitter.split_documents(docs) In\u00a0[8]: Copied! <pre>from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n\nHF_EMBED_MODEL_ID = \"BAAI/bge-small-en-v1.5\"\nembeddings = HuggingFaceEmbeddings(model_name=HF_EMBED_MODEL_ID)\n</pre> from langchain_huggingface.embeddings import HuggingFaceEmbeddings  HF_EMBED_MODEL_ID = \"BAAI/bge-small-en-v1.5\" embeddings = HuggingFaceEmbeddings(model_name=HF_EMBED_MODEL_ID) In\u00a0[9]: Copied! <pre>from tempfile import TemporaryDirectory\n\nfrom langchain_milvus import Milvus\n\nMILVUS_URI = os.environ.get(\n    \"MILVUS_URL\", f\"{(tmp_dir := TemporaryDirectory()).name}/milvus_demo.db\"\n)\n\nvectorstore = Milvus.from_documents(\n    splits,\n    embeddings,\n    connection_args={\"uri\": MILVUS_URI},\n    drop_old=True,\n)\n</pre> from tempfile import TemporaryDirectory  from langchain_milvus import Milvus  MILVUS_URI = os.environ.get(     \"MILVUS_URL\", f\"{(tmp_dir := TemporaryDirectory()).name}/milvus_demo.db\" )  vectorstore = Milvus.from_documents(     splits,     embeddings,     connection_args={\"uri\": MILVUS_URI},     drop_old=True, ) In\u00a0[10]: Copied! <pre>from langchain_huggingface import HuggingFaceEndpoint\n\nHF_API_KEY = os.environ.get(\"HF_API_KEY\")\nHF_LLM_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n\nllm = HuggingFaceEndpoint(\n    repo_id=HF_LLM_MODEL_ID,\n    huggingfacehub_api_token=HF_API_KEY,\n)\n</pre> from langchain_huggingface import HuggingFaceEndpoint  HF_API_KEY = os.environ.get(\"HF_API_KEY\") HF_LLM_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"  llm = HuggingFaceEndpoint(     repo_id=HF_LLM_MODEL_ID,     huggingfacehub_api_token=HF_API_KEY, ) <pre>The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /Users/pva/.cache/huggingface/token\nLogin successful\n</pre> In\u00a0[11]: Copied! <pre>from typing import Iterable\n\nfrom langchain_core.documents import Document as LCDocument\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\n\n\ndef format_docs(docs: Iterable[LCDocument]):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\nretriever = vectorstore.as_retriever()\n\nprompt = PromptTemplate.from_template(\n    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {question}\\nAnswer:\\n\"\n)\n\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n</pre> from typing import Iterable  from langchain_core.documents import Document as LCDocument from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import PromptTemplate from langchain_core.runnables import RunnablePassthrough   def format_docs(docs: Iterable[LCDocument]):     return \"\\n\\n\".join(doc.page_content for doc in docs)   retriever = vectorstore.as_retriever()  prompt = PromptTemplate.from_template(     \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {question}\\nAnswer:\\n\" )  rag_chain = (     {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}     | prompt     | llm     | StrOutputParser() ) In\u00a0[12]: Copied! <pre>rag_chain.invoke(\"How many pages were human annotated for DocLayNet?\")\n</pre> rag_chain.invoke(\"How many pages were human annotated for DocLayNet?\") Out[12]: <pre>'The human annotation of DocLayNet was performed on 80863 pages.\\n\\nExplanation:\\nThe information is found in the paragraph \"DocLayNet contains 80863 PDF pages\" in the context.'</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/rag_langchain/#rag-with-langchain","title":"RAG with LangChain \ud83e\udd9c\ud83d\udd17\u00b6","text":""},{"location":"examples/rag_langchain/#setup","title":"Setup\u00b6","text":""},{"location":"examples/rag_langchain/#loader-and-splitter","title":"Loader and splitter\u00b6","text":""},{"location":"examples/rag_langchain/#embeddings","title":"Embeddings\u00b6","text":""},{"location":"examples/rag_langchain/#vector-store","title":"Vector store\u00b6","text":""},{"location":"examples/rag_langchain/#llm","title":"LLM\u00b6","text":""},{"location":"examples/rag_langchain/#rag","title":"RAG\u00b6","text":""},{"location":"examples/rag_llamaindex/","title":"RAG with LlamaIndex \ud83e\udd99","text":"<p>This example leverages the official LlamaIndex Docling extension.</p> <p>Presented extensions <code>DoclingReader</code> and <code>DoclingNodeParser</code> enable you to:</p> <ul> <li>use PDF documents in your LLM applications with ease and speed, and</li> <li>harness Docling's rich format for advanced, document-native grounding.</li> </ul> <ul> <li>\ud83d\udc49 For best conversion speed, use GPU acceleration whenever available; e.g. if running on Colab, use GPU-enabled runtime.</li> <li>Notebook uses HuggingFace's Inference API; for increased LLM quota, token can be provided via env var <code>HF_TOKEN</code>.</li> <li>Requirements can be installed as shown below (<code>--no-warn-conflicts</code> meant for Colab's pre-populated Python env; feel free to remove for stricter usage):</li> </ul> In\u00a0[1]: Copied! <pre>%pip install -q --progress-bar off --no-warn-conflicts llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-readers-file python-dotenv\n</pre> %pip install -q --progress-bar off --no-warn-conflicts llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-readers-file python-dotenv <pre>Note: you may need to restart the kernel to use updated packages.\n</pre> In\u00a0[2]: Copied! <pre>import os\nfrom pathlib import Path\nfrom tempfile import mkdtemp\nfrom warnings import filterwarnings\n\nfrom dotenv import load_dotenv\n\n\ndef _get_env_from_colab_or_os(key):\n    try:\n        from google.colab import userdata\n\n        try:\n            return userdata.get(key)\n        except userdata.SecretNotFoundError:\n            pass\n    except ImportError:\n        pass\n    return os.getenv(key)\n\n\nload_dotenv()\n\nfilterwarnings(action=\"ignore\", category=UserWarning, module=\"pydantic\")\nfilterwarnings(action=\"ignore\", category=FutureWarning, module=\"easyocr\")\n# https://github.com/huggingface/transformers/issues/5486:\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n</pre> import os from pathlib import Path from tempfile import mkdtemp from warnings import filterwarnings  from dotenv import load_dotenv   def _get_env_from_colab_or_os(key):     try:         from google.colab import userdata          try:             return userdata.get(key)         except userdata.SecretNotFoundError:             pass     except ImportError:         pass     return os.getenv(key)   load_dotenv()  filterwarnings(action=\"ignore\", category=UserWarning, module=\"pydantic\") filterwarnings(action=\"ignore\", category=FutureWarning, module=\"easyocr\") # https://github.com/huggingface/transformers/issues/5486: os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" <p>We can now define the main parameters:</p> In\u00a0[3]: Copied! <pre>from llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n\nEMBED_MODEL = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\nMILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")\nGEN_MODEL = HuggingFaceInferenceAPI(\n    token=_get_env_from_colab_or_os(\"HF_TOKEN\"),\n    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\nSOURCE = \"https://arxiv.org/pdf/2408.09869\"  # Docling Technical Report\nQUERY = \"Which are the main AI models in Docling?\"\n\nembed_dim = len(EMBED_MODEL.get_text_embedding(\"hi\"))\n</pre> from llama_index.embeddings.huggingface import HuggingFaceEmbedding from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI  EMBED_MODEL = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\") MILVUS_URI = str(Path(mkdtemp()) / \"docling.db\") GEN_MODEL = HuggingFaceInferenceAPI(     token=_get_env_from_colab_or_os(\"HF_TOKEN\"),     model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", ) SOURCE = \"https://arxiv.org/pdf/2408.09869\"  # Docling Technical Report QUERY = \"Which are the main AI models in Docling?\"  embed_dim = len(EMBED_MODEL.get_text_embedding(\"hi\")) <p>To create a simple RAG pipeline, we can:</p> <ul> <li>define a <code>DoclingReader</code>, which by default exports to Markdown, and</li> <li>use a standard node parser for these Markdown-based docs, e.g. a <code>MarkdownNodeParser</code></li> </ul> In\u00a0[4]: Copied! <pre>from llama_index.core import StorageContext, VectorStoreIndex\nfrom llama_index.core.node_parser import MarkdownNodeParser\nfrom llama_index.readers.docling import DoclingReader\nfrom llama_index.vector_stores.milvus import MilvusVectorStore\n\nreader = DoclingReader()\nnode_parser = MarkdownNodeParser()\n\nvector_store = MilvusVectorStore(\n    uri=str(Path(mkdtemp()) / \"docling.db\"),  # or set as needed\n    dim=embed_dim,\n    overwrite=True,\n)\nindex = VectorStoreIndex.from_documents(\n    documents=reader.load_data(SOURCE),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n</pre> from llama_index.core import StorageContext, VectorStoreIndex from llama_index.core.node_parser import MarkdownNodeParser from llama_index.readers.docling import DoclingReader from llama_index.vector_stores.milvus import MilvusVectorStore  reader = DoclingReader() node_parser = MarkdownNodeParser()  vector_store = MilvusVectorStore(     uri=str(Path(mkdtemp()) / \"docling.db\"),  # or set as needed     dim=embed_dim,     overwrite=True, ) index = VectorStoreIndex.from_documents(     documents=reader.load_data(SOURCE),     transformations=[node_parser],     storage_context=StorageContext.from_defaults(vector_store=vector_store),     embed_model=EMBED_MODEL, ) result = index.as_query_engine(llm=GEN_MODEL).query(QUERY) print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\") display([(n.text, n.metadata) for n in result.source_nodes]) <pre>Q: Which are the main AI models in Docling?\nA: 1. A layout analysis model, an accurate object-detector for page elements. 2. TableFormer, a state-of-the-art table structure recognition model.\n\nSources:\n</pre> <pre>[('3.2 AI models\\n\\nAs part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.',\n  {'dl_doc_hash': '556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa',\n   'Header_2': '3.2 AI models'}),\n (\"5 Applications\\n\\nThanks to the high-quality, richly structured document conversion achieved by Docling, its output qualifies for numerous downstream applications. For example, Docling can provide a base for detailed enterprise document search, passage retrieval or classification use-cases, or support knowledge extraction pipelines, allowing specific treatment of different structures in the document, such as tables, figures, section structure or references. For popular generative AI application patterns, such as retrieval-augmented generation (RAG), we provide quackling , an open-source package which capitalizes on Docling's feature-rich document output to enable document-native optimized vector embedding and chunking. It plugs in seamlessly with LLM frameworks such as LlamaIndex [8]. Since Docling is fast, stable and cheap to run, it also makes for an excellent choice to build document-derived datasets. With its powerful table structure recognition, it provides significant benefit to automated knowledge-base construction [11, 10]. Docling is also integrated within the open IBM data prep kit [6], which implements scalable data transforms to build large-scale multi-modal training datasets.\",\n  {'dl_doc_hash': '556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa',\n   'Header_2': '5 Applications'})]</pre> <p>To leverage Docling's rich native format, we:</p> <ul> <li>create a <code>DoclingReader</code> with JSON export type, and</li> <li>employ a <code>DoclingNodeParser</code> in order to appropriately parse that Docling format.</li> </ul> <p>Notice how the sources now also contain document-level grounding (e.g. page number or bounding box information):</p> In\u00a0[5]: Copied! <pre>from llama_index.node_parser.docling import DoclingNodeParser\n\nreader = DoclingReader(export_type=DoclingReader.ExportType.JSON)\nnode_parser = DoclingNodeParser()\n\nvector_store = MilvusVectorStore(\n    uri=str(Path(mkdtemp()) / \"docling.db\"),  # or set as needed\n    dim=embed_dim,\n    overwrite=True,\n)\nindex = VectorStoreIndex.from_documents(\n    documents=reader.load_data(SOURCE),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n</pre> from llama_index.node_parser.docling import DoclingNodeParser  reader = DoclingReader(export_type=DoclingReader.ExportType.JSON) node_parser = DoclingNodeParser()  vector_store = MilvusVectorStore(     uri=str(Path(mkdtemp()) / \"docling.db\"),  # or set as needed     dim=embed_dim,     overwrite=True, ) index = VectorStoreIndex.from_documents(     documents=reader.load_data(SOURCE),     transformations=[node_parser],     storage_context=StorageContext.from_defaults(vector_store=vector_store),     embed_model=EMBED_MODEL, ) result = index.as_query_engine(llm=GEN_MODEL).query(QUERY) print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\") display([(n.text, n.metadata) for n in result.source_nodes]) <pre>Q: Which are the main AI models in Docling?\nA: The main AI models in Docling are a layout analysis model and TableFormer. The layout analysis model is an accurate object-detector for page elements, and TableFormer is a state-of-the-art table structure recognition model.\n\nSources:\n</pre> <pre>[('As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.',\n  {'dl_doc_hash': '556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa',\n   'path': '#/main-text/37',\n   'heading': '3.2 AI models',\n   'page': 3,\n   'bbox': [107.36903381347656,\n    330.07513427734375,\n    506.29705810546875,\n    407.3725280761719]}),\n ('With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.',\n  {'dl_doc_hash': '556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa',\n   'path': '#/main-text/10',\n   'heading': '1 Introduction',\n   'page': 1,\n   'bbox': [107.33261108398438,\n    83.3067626953125,\n    504.0033874511719,\n    136.45367431640625]})]</pre> <p>To demonstrate this usage pattern, we first set up a test document directory.</p> In\u00a0[6]: Copied! <pre>from pathlib import Path\nfrom tempfile import mkdtemp\n\nimport requests\n\ntmp_dir_path = Path(mkdtemp())\nr = requests.get(SOURCE)\nwith open(tmp_dir_path / f\"{Path(SOURCE).name}.pdf\", \"wb\") as out_file:\n    out_file.write(r.content)\n</pre> from pathlib import Path from tempfile import mkdtemp  import requests  tmp_dir_path = Path(mkdtemp()) r = requests.get(SOURCE) with open(tmp_dir_path / f\"{Path(SOURCE).name}.pdf\", \"wb\") as out_file:     out_file.write(r.content) <p>Using the <code>reader</code> and <code>node_parser</code> definitions from any of the above variants, usage with <code>SimpleDirectoryReader</code> then looks as follows:</p> In\u00a0[7]: Copied! <pre>from llama_index.core import SimpleDirectoryReader\n\ndir_reader = SimpleDirectoryReader(\n    input_dir=tmp_dir_path,\n    file_extractor={\".pdf\": reader},\n)\n\nvector_store = MilvusVectorStore(\n    uri=str(Path(mkdtemp()) / \"docling.db\"),  # or set as needed\n    dim=embed_dim,\n    overwrite=True,\n)\nindex = VectorStoreIndex.from_documents(\n    documents=dir_reader.load_data(SOURCE),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n</pre> from llama_index.core import SimpleDirectoryReader  dir_reader = SimpleDirectoryReader(     input_dir=tmp_dir_path,     file_extractor={\".pdf\": reader}, )  vector_store = MilvusVectorStore(     uri=str(Path(mkdtemp()) / \"docling.db\"),  # or set as needed     dim=embed_dim,     overwrite=True, ) index = VectorStoreIndex.from_documents(     documents=dir_reader.load_data(SOURCE),     transformations=[node_parser],     storage_context=StorageContext.from_defaults(vector_store=vector_store),     embed_model=EMBED_MODEL, ) result = index.as_query_engine(llm=GEN_MODEL).query(QUERY) print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\") display([(n.text, n.metadata) for n in result.source_nodes]) <pre>Loading files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:11&lt;00:00, 11.15s/file]\n</pre> <pre>Q: Which are the main AI models in Docling?\nA: The main AI models in Docling are a layout analysis model and TableFormer. The layout analysis model is an accurate object-detector for page elements, and TableFormer is a state-of-the-art table structure recognition model.\n\nSources:\n</pre> <pre>[('As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.',\n  {'file_path': '/var/folders/76/4wwfs06x6835kcwj4186c0nc0000gn/T/tmp4vsev3_r/2408.09869.pdf',\n   'file_name': '2408.09869.pdf',\n   'file_type': 'application/pdf',\n   'file_size': 5566574,\n   'creation_date': '2024-10-09',\n   'last_modified_date': '2024-10-09',\n   'dl_doc_hash': '556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa',\n   'path': '#/main-text/37',\n   'heading': '3.2 AI models',\n   'page': 3,\n   'bbox': [107.36903381347656,\n    330.07513427734375,\n    506.29705810546875,\n    407.3725280761719]}),\n ('With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.',\n  {'file_path': '/var/folders/76/4wwfs06x6835kcwj4186c0nc0000gn/T/tmp4vsev3_r/2408.09869.pdf',\n   'file_name': '2408.09869.pdf',\n   'file_type': 'application/pdf',\n   'file_size': 5566574,\n   'creation_date': '2024-10-09',\n   'last_modified_date': '2024-10-09',\n   'dl_doc_hash': '556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa',\n   'path': '#/main-text/10',\n   'heading': '1 Introduction',\n   'page': 1,\n   'bbox': [107.33261108398438,\n    83.3067626953125,\n    504.0033874511719,\n    136.45367431640625]})]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/rag_llamaindex/#rag-with-llamaindex","title":"RAG with LlamaIndex \ud83e\udd99\u00b6","text":""},{"location":"examples/rag_llamaindex/#overview","title":"Overview\u00b6","text":""},{"location":"examples/rag_llamaindex/#setup","title":"Setup\u00b6","text":""},{"location":"examples/rag_llamaindex/#using-markdown-export","title":"Using Markdown export\u00b6","text":""},{"location":"examples/rag_llamaindex/#using-docling-format","title":"Using Docling format\u00b6","text":""},{"location":"examples/rag_llamaindex/#with-simple-directory-reader","title":"With Simple Directory Reader\u00b6","text":""},{"location":"integrations/llamaindex/","title":"LlamaIndex \ud83e\udd99 extension","text":""},{"location":"integrations/llamaindex/#get-started","title":"Get started","text":"<p>Docling is available as an official LlamaIndex extension!</p> <p>To get started, check out the step-by-step guide in LlamaIndex [\u2197].</p>"},{"location":"integrations/llamaindex/#components","title":"Components","text":""},{"location":"integrations/llamaindex/#docling-reader","title":"Docling Reader","text":"<p>Reads document files and uses Docling to populate LlamaIndex <code>Document</code> objects \u2014 either serializing Docling's data model (losslessly, e.g. as JSON) or exporting to a simplified format (lossily, e.g. as Markdown).</p> <ul> <li>\ud83d\udcbb GitHub [\u2197]</li> <li>\ud83d\udcd6 API docs [\u2197]</li> <li>\ud83d\udce6 PyPI [\u2197]</li> <li>\ud83e\udd99 LlamaHub [\u2197]</li> </ul>"},{"location":"integrations/llamaindex/#docling-node-parser","title":"Docling Node Parser","text":"<p>Reads LlamaIndex <code>Document</code> objects populated in Docling's format by Docling Reader and, using its knowledge of the Docling format, parses them to LlamaIndex <code>Node</code> objects for downstream usage in LlamaIndex applications, e.g. as chunks for embedding.</p> <ul> <li>\ud83d\udcbb GitHub [\u2197]</li> <li>\ud83d\udcd6 API docs [\u2197]</li> <li>\ud83d\udce6 PyPI [\u2197]</li> <li>\ud83e\udd99 LlamaHub [\u2197]</li> </ul>"}]}